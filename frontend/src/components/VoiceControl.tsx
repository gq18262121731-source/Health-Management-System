/**
 * è¯­éŸ³æ§åˆ¶ç»„ä»¶
 * æ”¯æŒå”¤é†’è¯æ£€æµ‹ã€è¯­éŸ³å‘½ä»¤ã€æƒ…æ„Ÿåˆ†æ
 */
import React, { useState, useRef, useCallback, useEffect } from 'react';
import { Mic, MicOff, Volume2, Loader2, AlertCircle } from 'lucide-react';

// æ”¯æŒçš„å”¤é†’è¯
const WAKE_WORDS = ['ç³–è±†ç³–è±†', 'ç³–è±†', 'ä½ å¥½ç³–è±†'];

interface VoiceControlProps {
  onCommand?: (command: VoiceCommandResult) => void;
  onNavigate?: (route: string) => void;
  onEmergency?: () => void;
  className?: string;
}

interface VoiceCommandResult {
  text: string;
  response: string;
  audioUrl?: string;
  isControl: boolean;
  controlEvent?: string;
  controlData?: Record<string, any>;
  emotion?: string;
  agent?: string;
}

export const VoiceControl: React.FC<VoiceControlProps> = ({
  onCommand,
  onNavigate,
  onEmergency,
  className = '',
}) => {
  const [isListening, setIsListening] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isAwake, setIsAwake] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [response, setResponse] = useState('');
  const [error, setError] = useState('');
  
  const recognitionRef = useRef<any>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const awakeTimeoutRef = useRef<NodeJS.Timeout | null>(null);

  // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«ï¼ˆä½¿ç”¨æµè§ˆå™¨Web Speech APIï¼‰
  useEffect(() => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = true;
      recognitionRef.current.interimResults = true;
      recognitionRef.current.lang = 'zh-CN';

      recognitionRef.current.onresult = (event: any) => {
        let finalTranscript = '';
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          }
        }
        if (finalTranscript) {
          handleVoiceInput(finalTranscript);
        }
      };

      recognitionRef.current.onerror = (event: any) => {
        console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
        if (event.error !== 'no-speech') {
          setError('è¯­éŸ³è¯†åˆ«å‡ºé”™ï¼Œè¯·é‡è¯•');
        }
      };

      recognitionRef.current.onend = () => {
        if (isListening) {
          // è‡ªåŠ¨é‡å¯
          try {
            recognitionRef.current?.start();
          } catch (e) {
            console.log('é‡å¯è¯­éŸ³è¯†åˆ«');
          }
        }
      };
    } else {
      setError('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«');
    }

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      if (awakeTimeoutRef.current) {
        clearTimeout(awakeTimeoutRef.current);
      }
    };
  }, [isListening]);

  // å¤„ç†è¯­éŸ³è¾“å…¥
  const handleVoiceInput = async (text: string) => {
    setTranscript(text);
    setError('');

    // æ£€æµ‹å”¤é†’è¯
    const isWakeWord = WAKE_WORDS.some(w => text.includes(w));
    
    if (isWakeWord) {
      setIsAwake(true);
      // ç§»é™¤å”¤é†’è¯
      let cleanText = text;
      WAKE_WORDS.forEach(w => {
        cleanText = cleanText.replace(w, '').trim();
      });
      // å»é™¤å¼€å¤´çš„æ ‡ç‚¹
      cleanText = cleanText.replace(/^[,ï¼Œã€‚ï¼ï¼Ÿã€]+/, '').trim();

      // é‡ç½®å”¤é†’è¶…æ—¶
      if (awakeTimeoutRef.current) {
        clearTimeout(awakeTimeoutRef.current);
      }
      awakeTimeoutRef.current = setTimeout(() => {
        setIsAwake(false);
      }, 30000); // 30ç§’åè‡ªåŠ¨ä¼‘çœ 

      if (!cleanText) {
        // åªæœ‰å”¤é†’è¯ï¼Œæ’­æ”¾é—®å€™
        setResponse('æˆ‘åœ¨å‘¢ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ');
        speak('æˆ‘åœ¨å‘¢ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ');
        return;
      }

      // å¤„ç†å®é™…å‘½ä»¤
      await processCommand(cleanText);
    } else if (isAwake) {
      // å·²å”¤é†’çŠ¶æ€ï¼Œç›´æ¥å¤„ç†å‘½ä»¤
      await processCommand(text);
      
      // é‡ç½®å”¤é†’è¶…æ—¶
      if (awakeTimeoutRef.current) {
        clearTimeout(awakeTimeoutRef.current);
      }
      awakeTimeoutRef.current = setTimeout(() => {
        setIsAwake(false);
      }, 30000);
    }
  };

  // å¤„ç†å‘½ä»¤
  const processCommand = async (text: string) => {
    setIsProcessing(true);
    try {
      // è°ƒç”¨åç«¯APIè¿›è¡Œæ„å›¾è¯†åˆ«å’Œå¤„ç†
      const formData = new FormData();
      // ç”±äºä½¿ç”¨æµè§ˆå™¨è¯­éŸ³è¯†åˆ«ï¼Œç›´æ¥å‘é€æ–‡æœ¬
      const response = await fetch('/api/v1/voice-agent/text-command', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          text, 
          user_role: 'elderly',
          voice_style: 'default'
        }),
      });

      if (!response.ok) {
        throw new Error('è¯·æ±‚å¤±è´¥');
      }

      const result = await response.json();
      
      setResponse(result.response || '');
      
      // æ’­æ”¾è¯­éŸ³å›å¤
      if (result.audio_url) {
        playAudio(result.audio_url);
      } else if (result.response) {
        speak(result.response);
      }

      // å¤„ç†æ§åˆ¶å‘½ä»¤
      if (result.is_control) {
        handleControlEvent(result.control_event, result.control_data);
      }

      // å›è°ƒ
      onCommand?.(result);

    } catch (err) {
      console.error('å¤„ç†å‘½ä»¤å¤±è´¥:', err);
      // æœ¬åœ°å¤„ç†ç®€å•å‘½ä»¤
      handleLocalCommand(text);
    } finally {
      setIsProcessing(false);
    }
  };

  // æœ¬åœ°å‘½ä»¤å¤„ç†ï¼ˆAPIå¤±è´¥æ—¶çš„fallbackï¼‰
  const handleLocalCommand = (text: string) => {
    const lowerText = text.toLowerCase();
    
    // ç´§æ€¥å‘¼æ•‘
    if (['æ•‘å‘½', 'å¸®å¸®æˆ‘', 'å‘¼æ•‘', 'ä¸€é”®å‘¼æ•‘'].some(w => lowerText.includes(w))) {
      setResponse('ğŸš¨ ç´§æ€¥å‘¼æ•‘å·²è§¦å‘ï¼æ­£åœ¨é€šçŸ¥æ‚¨çš„ç´§æ€¥è”ç³»äººï¼');
      speak('ç´§æ€¥å‘¼æ•‘å·²è§¦å‘ï¼æ­£åœ¨é€šçŸ¥æ‚¨çš„ç´§æ€¥è”ç³»äººï¼');
      onEmergency?.();
      return;
    }

    // å¯¼èˆªå‘½ä»¤
    const navCommands: Record<string, string> = {
      'é¦–é¡µ': '/home',
      'ä¸»é¡µ': '/home',
      'æŠ¥å‘Š': '/report',
      'å¥åº·æŠ¥å‘Š': '/report',
      'è®¾ç½®': '/settings',
      'è¿”å›': 'back',
    };

    for (const [keyword, route] of Object.entries(navCommands)) {
      if (lowerText.includes(keyword)) {
        setResponse(`å¥½çš„ï¼Œæ­£åœ¨ä¸ºæ‚¨æ‰“å¼€${keyword}`);
        speak(`å¥½çš„ï¼Œæ­£åœ¨ä¸ºæ‚¨æ‰“å¼€${keyword}`);
        onNavigate?.(route);
        return;
      }
    }

    // æ— æ³•è¯†åˆ«
    setResponse('æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰å¬æ¸…æ¥šï¼Œè¯·å†è¯´ä¸€é');
    speak('æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰å¬æ¸…æ¥šï¼Œè¯·å†è¯´ä¸€é');
  };

  // å¤„ç†æ§åˆ¶äº‹ä»¶
  const handleControlEvent = (event: string, data: Record<string, any>) => {
    switch (event) {
      case 'navigate':
        onNavigate?.(data.route);
        break;
      case 'emergency_call':
        onEmergency?.();
        break;
      case 'query_data':
        // å¯ä»¥è§¦å‘æ•°æ®æŸ¥è¯¢
        console.log('æŸ¥è¯¢æ•°æ®:', data.type);
        break;
      case 'volume_control':
        // éŸ³é‡æ§åˆ¶
        console.log('éŸ³é‡æ§åˆ¶:', data.action);
        break;
    }
  };

  // æ’­æ”¾éŸ³é¢‘
  const playAudio = (url: string) => {
    if (audioRef.current) {
      audioRef.current.src = url;
      audioRef.current.play().catch(console.error);
    }
  };

  // ä½¿ç”¨æµè§ˆå™¨TTSæœ—è¯»
  const speak = (text: string) => {
    if ('speechSynthesis' in window) {
      // åœæ­¢å½“å‰æ’­æ”¾
      window.speechSynthesis.cancel();
      
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'zh-CN';
      utterance.rate = 0.9; // ç¨æ…¢è¯­é€Ÿ
      utterance.pitch = 1;
      utterance.volume = 1;
      
      window.speechSynthesis.speak(utterance);
    }
  };

  // å¼€å§‹/åœæ­¢ç›‘å¬
  const toggleListening = useCallback(() => {
    if (isListening) {
      recognitionRef.current?.stop();
      setIsListening(false);
      setIsAwake(false);
    } else {
      try {
        recognitionRef.current?.start();
        setIsListening(true);
        setError('');
      } catch (e) {
        console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', e);
      }
    }
  }, [isListening]);

  return (
    <div className={`voice-control ${className}`}>
      {/* éšè—çš„éŸ³é¢‘æ’­æ”¾å™¨ */}
      <audio ref={audioRef} className="hidden" />
      
      {/* è¯­éŸ³æ§åˆ¶æŒ‰é’® */}
      <div className="flex flex-col items-center gap-3">
        <button
          onClick={toggleListening}
          disabled={isProcessing}
          className={`
            relative w-20 h-20 rounded-full flex items-center justify-center
            transition-all duration-300 shadow-lg
            ${isListening 
              ? isAwake 
                ? 'bg-green-500 hover:bg-green-600 animate-pulse' 
                : 'bg-blue-500 hover:bg-blue-600'
              : 'bg-gray-400 hover:bg-gray-500'
            }
            ${isProcessing ? 'opacity-70 cursor-wait' : 'cursor-pointer'}
          `}
        >
          {isProcessing ? (
            <Loader2 className="w-10 h-10 text-white animate-spin" />
          ) : isListening ? (
            <Mic className="w-10 h-10 text-white" />
          ) : (
            <MicOff className="w-10 h-10 text-white" />
          )}
          
          {/* å”¤é†’çŠ¶æ€æŒ‡ç¤ºå™¨ */}
          {isAwake && (
            <span className="absolute -top-1 -right-1 w-4 h-4 bg-yellow-400 rounded-full animate-ping" />
          )}
        </button>

        {/* çŠ¶æ€æ–‡å­— */}
        <div className="text-center">
          <p className="text-sm font-medium text-gray-700">
            {isProcessing ? 'å¤„ç†ä¸­...' : 
             isAwake ? 'ğŸŸ¢ å·²å”¤é†’ï¼Œè¯·è¯´è¯' : 
             isListening ? 'ğŸ¤ è¯´"ç³–è±†ç³–è±†"å”¤é†’æˆ‘' : 
             'ç‚¹å‡»å¼€å§‹è¯­éŸ³'}
          </p>
          {transcript && (
            <p className="text-xs text-gray-500 mt-1 max-w-48 truncate">
              æ‚¨è¯´: {transcript}
            </p>
          )}
        </div>

        {/* å›å¤æ˜¾ç¤º */}
        {response && (
          <div className="mt-2 p-3 bg-blue-50 rounded-lg max-w-64">
            <div className="flex items-start gap-2">
              <Volume2 className="w-4 h-4 text-blue-500 mt-0.5 flex-shrink-0" />
              <p className="text-sm text-gray-700">{response}</p>
            </div>
          </div>
        )}

        {/* é”™è¯¯æç¤º */}
        {error && (
          <div className="mt-2 p-2 bg-red-50 rounded-lg flex items-center gap-2">
            <AlertCircle className="w-4 h-4 text-red-500" />
            <p className="text-xs text-red-600">{error}</p>
          </div>
        )}
      </div>
    </div>
  );
};

export default VoiceControl;
